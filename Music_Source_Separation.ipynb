{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music Source Separation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_KHdBaFRHP2EpICwazP74WAQ2w4zowj8",
      "authorship_tag": "ABX9TyPZ14fI2tqmWT9ilNKpNdjB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrpep/music-source-separation-4all/blob/main/Music_Source_Separation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx7C_lx-AUBh",
        "cellView": "form"
      },
      "source": [
        "#@title Install dependencies \n",
        "%%capture\n",
        "%%bash\n",
        "\n",
        "pip install torchaudio==0.10.0+cu111 torch==1.10.0+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html\n",
        "pip install demucs\n",
        "pip install youtube-dl\n",
        "pip install ffmpeg-python\n",
        "pip install openunmix\n",
        "pip install typer\n",
        "pip install httpx[http2]==0.19.0\n",
        "pip install --no-deps spleeter\n",
        "git clone https://github.com/pfnet-research/meta-tasnet\n",
        "wget \"https://www.dropbox.com/s/zw6zgt3edd88v87/best_model.pt\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJlHalWL--PC",
        "cellView": "form"
      },
      "source": [
        "#@title Enter nerd mode\n",
        "from demucs.pretrained import get_model\n",
        "from demucs.apply import apply_model\n",
        "import torch\n",
        "from youtube_dl import YoutubeDL\n",
        "import ffmpeg\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.append(\"/content/meta-tasnet\")\n",
        "\n",
        "from model.tasnet import MultiTasNet\n",
        "import librosa\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "def download_from_youtube(url,start,end,sr=44100):\n",
        "  with YoutubeDL(dict(format='bestaudio')) as ydl:\n",
        "    video_url = ydl.extract_info(url, download=False)['formats'][0]['url']\n",
        "  kwargs = {}\n",
        "  if start > 0:\n",
        "    kwargs['ss'] = start\n",
        "  if end > 0:\n",
        "    kwargs['t'] = end - start\n",
        "  out,_ = ffmpeg.input(video_url,**kwargs).output('-', format='s16le', acodec='pcm_s16le', ac=2, ar=sr).overwrite_output().run(capture_stdout=True)\n",
        "  y = np.frombuffer(out,dtype='int16')\n",
        "  y = np.reshape(y,(len(y)//2,2))/(2**15 - 1)\n",
        "  return y\n",
        "\n",
        "def demucs_separate(x, shifts=1, models=None):\n",
        "  if 'mdx_extra_q' in models:\n",
        "    model = models['mdx_extra_q']\n",
        "  else:\n",
        "    model = get_model(name='mdx_extra_q')\n",
        "    models['mdx_extra_q'] = model\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  x = x.T\n",
        "  x = np.expand_dims(x,0)\n",
        "  x = torch.from_numpy(x)\n",
        "  x = x.to(device, dtype=torch.float32)\n",
        "  ref = x.mean(0)\n",
        "  x = (x - ref.mean())/ref.std()\n",
        "  sources = apply_model(model,x,shifts=shifts,split=True,overlap=0.25,progress=True)[0]\n",
        "  sources = sources * ref.std() + ref.mean()\n",
        "  sources = sources.detach().to('cpu').numpy()\n",
        "\n",
        "  return sources\n",
        "\n",
        "def openumx_separate(x,split_size=30, split_overlap=1, models=None):\n",
        "  if 'umxl' in models:\n",
        "    separator = models['umxl']\n",
        "  else:\n",
        "    separator = torch.hub.load('sigsep/open-unmix-pytorch', 'umxl', device='cuda')\n",
        "    models['umxl'] = separator\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  separator.to(device)\n",
        "  fs = 44100\n",
        "  x = x.T\n",
        "  x = x[np.newaxis,:,:]\n",
        "  split_frames = int(split_size*fs)\n",
        "  x_splits = np.concatenate([x[:,:,i:i+split_frames] for i in range(0,x.shape[-1]-split_frames,int(split_frames*split_overlap))],axis=0)\n",
        "  sources_splits = []\n",
        "  for split in x_splits:\n",
        "    sources = separator(torch.tensor(split).unsqueeze(0).to(device,dtype=torch.float32))\n",
        "    sources = sources.detach().cpu().numpy()\n",
        "    sources_splits.append(sources)\n",
        "  sources = np.concatenate(sources_splits,axis = -1)\n",
        "  return sources\n",
        "\n",
        "def metatasnet_separate(x,models=None):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  rate=44100\n",
        "  if 'metatasnet' in models:\n",
        "    model = models['metatasnet']\n",
        "  else:\n",
        "    state = torch.load(\"best_model.pt\")  # load checkpoint\n",
        "    model = MultiTasNet(state[\"args\"]).to(device)  # initialize the model\n",
        "    model.load_state_dict(state['state_dict'])  # load weights from the checkpoint\n",
        "  \n",
        "  def resample(audio, target_rate):\n",
        "    return librosa.core.resample(audio, rate, target_rate, res_type='kaiser_best', fix=False)\n",
        "    \n",
        "  \n",
        "  x = x.astype('float32')  # match the type with the type of the weights in the network\n",
        "  x = x.T\n",
        "  mix = [resample(x, s) for s in[8000, 16000, 32000]]  # resample to different sampling rates for the three stages\n",
        "  mix = [librosa.util.fix_length(m, (mix[0].shape[-1]+1)*(2**i)) for i,m in enumerate(mix)]  # allign all three sample so that their lenghts are divisible\n",
        "  mix = [torch.from_numpy(s).float().to(device).view(1, 1, -1) for s in mix]  # cast to tensor with shape: [1, 1, T']\n",
        "  mix = [s / s.std(dim=-1, keepdim=True) for s in mix]  # normalize by the standard deviation\n",
        "\n",
        "  model.eval()\n",
        "  n_chunks = x.shape[0]//(30*44100)\n",
        "  with torch.no_grad():        \n",
        "    sources = model.inference(mix, n_chunks=n_chunks)[-1]  # call the network to obtain the separated audio with shape [1, 4, 1, T']\n",
        "\n",
        "  # normalize the amplitudes by computing the least squares\n",
        "  # -> we try to scale the separated stems so that their sum is equal to the input mix \n",
        "  a = sources[0,:,0,:].cpu().numpy().T  # separated stems\n",
        "  b = mix[-1][0,0,:].cpu().numpy()  # input mix\n",
        "  sol = np.linalg.lstsq(a, b, rcond=None)[0]  # scaling coefficients that minimize the MSE\n",
        "  sources = a * sol  # scale the separated stems\n",
        "\n",
        "  return sources\n",
        "\n",
        "def spleeter_separate(x):\n",
        "  pass\n",
        "\n",
        "yt_cache_path = Path('youtube_cache')\n",
        "if not yt_cache_path.exists():\n",
        "  yt_cache_path.mkdir(parents=True)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpdTgpAZAcbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "b3e13202-f4a5-4df4-846a-7c9772d4309e"
      },
      "source": [
        "#@title Separate!\n",
        "model = \"demucs\" #@param [\"demucs\", \"open-umx\",\"meta-tasnet\",\"spleeter-2stems\",\"spleeter-4stems\",\"spleeter-5stems\"]\n",
        "youtube_link = \"i7AbCva8e7o\" #@param {type:\"string\"}\n",
        "youtube_start = 40 #@param {type:\"integer\"}\n",
        "youtube_end =  120#@param {type:\"integer\"}\n",
        "quality = 1 #@param {type: \"integer\"}\n",
        "\n",
        "sampling_rate=44100\n",
        "models = {}\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "if youtube_link == \"\":\n",
        "  from google.colab import files \n",
        "  uploaded = files.upload()\n",
        "  mix, fs = librosa.core.load(uploaded,sr=sampling_rate,mono=False)\n",
        "  mix = mix.T\n",
        "  youtube_link = Path(uploaded).stem\n",
        "else:\n",
        "  video_cache_path = Path(yt_cache_path,'{}.wav'.format(youtube_link))\n",
        "  if video_cache_path.exists():\n",
        "    print('Cacheando video...')\n",
        "    mix, _ = sf.read(str(video_cache_path.absolute()))\n",
        "  else:\n",
        "    print('Bajando de youtube...')\n",
        "    mix = download_from_youtube(youtube_link, youtube_start,youtube_end,sr=sampling_rate)\n",
        "    sf.write(video_cache_path,mix,samplerate=sampling_rate)\n",
        "if model == 'demucs':\n",
        "  sources = demucs_separate(mix,models=models,shifts=quality)\n",
        "  source_names = ['Drums','Bass','Other','Vocals']\n",
        "  source_fs=44100\n",
        "elif model == 'open-umx':\n",
        "  sources = openumx_separate(mix,models=models)[0]\n",
        "  source_names = ['Vocals','Drums','Bass','Other']\n",
        "  source_fs=44100\n",
        "elif model == 'meta-tasnet':\n",
        "  if mix.ndim == 2:\n",
        "    ch_sources = []\n",
        "    for ch in mix.T:\n",
        "      ch_i = metatasnet_separate(ch,models)\n",
        "      ch_sources.append(np.expand_dims(ch_i,0))\n",
        "    sources = np.concatenate(ch_sources,axis=0)\n",
        "    sources = np.transpose(sources,(2,0,1))\n",
        "  else:\n",
        "    sources = metatasnet_separate(ch,models)\n",
        "  source_names = ['Bass','Drums','Vocals','Other']\n",
        "  source_fs=32000\n",
        "elif model == 'spleeter-2stems':\n",
        "  command = \"spleeter separate -p spleeter:2stems -o outputs/spleeter-2stems youtube_cache/{}.wav\".format(youtube_link)\n",
        "  !$command\n",
        "elif model == 'spleeter-4stems':\n",
        "  command = \"spleeter separate -p spleeter:4stems -o outputs/spleeter-4stems youtube_cache/{}.wav\".format(youtube_link)\n",
        "  !$command\n",
        "elif model == 'spleeter-5stems':\n",
        "  command = \"spleeter separate -p spleeter:5stems -o outputs/spleeter-5stems youtube_cache/{}.wav\".format(youtube_link)\n",
        "  !$command\n",
        "\n",
        "if not model.startswith('spleeter'):\n",
        "  if not Path('outputs/{}/{}'.format(model,youtube_link)).exists():\n",
        "    Path('outputs/{}/{}'.format(model,youtube_link)).mkdir(parents=True)\n",
        "  for source_name, source in zip(source_names,sources):\n",
        "    sf.write('outputs/{}/{}/{}.wav'.format(model,youtube_link,source_name),source.T,source_fs)\n",
        "  #print(source_name)\n",
        "  #display(Audio(source,rate=44100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bajando de youtube...\n",
            "[youtube] i7AbCva8e7o: Downloading webpage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████| 99.0/99.0 [00:04<00:00, 20.58seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████████| 99.0/99.0 [00:04<00:00, 20.13seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████████| 99.0/99.0 [00:04<00:00, 20.13seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████████| 99.0/99.0 [00:04<00:00, 20.88seconds/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-dv0XEZtn8q"
      },
      "source": [
        "Audio('outputs/demucs/i7AbCva8e7o/Drums.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_pGmhhRSeFH"
      },
      "source": [
        "Audio('outputs/demucs/i7AbCva8e7o/Bass.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo2IafV1SpKq"
      },
      "source": [
        "Audio('outputs/demucs/i7AbCva8e7o/Other.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yjSm15JSsbf"
      },
      "source": [
        "Audio('outputs/demucs/i7AbCva8e7o/Vocals.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKNW0N6-Ecd-"
      },
      "source": [
        "### Transcripcion multipista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG7uRntZK8LL"
      },
      "source": [
        "%%capture\n",
        "%%bash\n",
        "\n",
        "pip install --no-deps omnizart\n",
        "pip install pretty_midi\n",
        "omnizart download-checkpoints\n",
        "pip install mido\n",
        "pip install madmom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKD3PmxhdW1E"
      },
      "source": [
        "from omnizart.music import app as mapp\n",
        "from omnizart.drum import app as dapp\n",
        "mapp.transcribe('outputs/demucs/a1TGCp9DDLU/Bass.wav')\n",
        "dapp.transcribe('outputs/demucs/a1TGCp9DDLU/Drums.wav')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}